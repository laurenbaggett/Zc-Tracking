---
title: "Tracking_GAM_perSite_LMB_siteE"
author: "Lauren M Baggett"
date: "2024-05-10"
output: pdf_document
---

```{r settings setup}
# load relevent packages
library(mgcv)
library(splus2R)
library(car)
library(FSA)

# read in data
df = read.csv("F:/Tracking/groups/bigmodel/SOCAL_total_binned_groups.csv")

# subset by site
e = df[which(df$site=="E"),]
```

Now, make a model per site!

Site E:
```{r site W autocorrelation}

# make 0s Nas
e[which(e$groupSize==0),4] = NA

# check autocorrelation factor
e$groupSize = as.numeric(e$groupSize)
# make a histogram to show the distribution
hist(e$groupSize)

glmod1 = glm(e$groupSize~e$dayNight+e$jd,family=poisson)
summary(glmod1)
# check acf on the residuals
all_acf = acf(residuals(glmod1),300)

sig = qnorm((1+0.95)/2)/sqrt(sum(!is.na(residuals(glmod1))))
sig
idx = which(all_acf$acf < sig)[1]
all_acf$lag[idx]

```

For site E, lag is 4. 4*25 = 100 minutes. Rebin and then continue on.

```{r rebinned, echo=TRUE}
# rebin to match the earlier lag value

df = read.csv("F:/Tracking/groups/siteEmod/SOCAL_E_binned_100min_groups.csv")

# replace zeros with Nas just to give it a go
zeros = which(df$groupSize==0)
df$groupSize[zeros] = NA

dfMod = df[-which(is.na(df$groupSize)),]
dfMod$jd = as.numeric(dfMod$jd)
dfMod$dayNight = as.factor(dfMod$dayNight)
dfMod$presBins = as.numeric(dfMod$presBins)

# check to see if anything is collinear
lm1 = lm(groupSize~jd+presBins,data=dfMod)
car::vif(lm1)
#       jd presBins 
# 1.029441 1.029441
# not collinear, move on

# check whether presence bins should be linear or a smooth
m1 = gam(groupSize~presBins,data=dfMod,family=tw(),method='REML')
m2 = gam(groupSize~s(presBins,bs='ts'),data=dfMod,family=tw(),method='REML')
aic1 = AIC(m1)
aic2 = AIC(m2)
# linear has lower AIC

# test to make sure isn't normal
shapiro.test(dfMod$groupSize)
# 	Shapiro-Wilk normality test
# 
# data:  dfMod$groupSize
# W = 0.87105, p-value < 2.2e-16
# data isn't normal

fullModel = gam(groupSize~
                  + s(dfMod$jd,bs='cc')
                  + dayNight
                  + presBins,
                data=dfMod,family=tw(),method='REML')

selectedCovariates = c("s(jd,bs='cc')", "dayNight","presBins")
namesCovariates = c("jd","daynight","pres")
iVarList = 1:length(selectedCovariates)
NVars = length(selectedCovariates)

# Backward selection:
# to start, you are running a full model with all non-collinear variables.
# then, the for loop runs the gams, removing a single variable (going through each potential one)
# look at the model with the lowest AIC-what variable was removed?
# branch off from there, run the for loop again, removing another variable (going through each one)
# keep doing this as long as the AIC value continues to decrease
# once AIC is increasing, go back to the last set of models run and select the last model ran
# "Removed"=variable(s) not included in the model
# "Idx" = variables included in the model
# ------------------------------------------------------------------------------
backSelection1 = matrix(0, ncol=3, nrow=NVars+1)
colnames(backSelection1) = c("Removed","Idx Vars", "AIC")
# 1st full model
backSelection1[NVars+1,1] = "None excluded"
backSelection1[NVars+1,2] = paste(iVarList,collapse=" ")
backSelection1[NVars+1,3] = AIC(fullModel)

# Remove one variable at a time
for (x in 1: length (selectedCovariates)){
  gc()
  iselected = iVarList[-c(x)]
  iselected = iselected[order(iselected,decreasing = FALSE)]
  newformula = as.formula(paste("groupSize ~", paste(selectedCovariates[iselected], collapse = " + ")))
  m = gam(as.formula (newformula),data=dfMod,family=tw(),method="REML") 
  backSelection1[x,1] = namesCovariates[x]
  backSelection1[x,2] = paste(iselected,collapse=" ")
  backSelection1[x,3] = AIC(m)
}
backSelection1[order(backSelection1[,3],decreasing=FALSE),]
#      Removed         Idx Vars AIC               
# [1,] "None excluded" "1 2 3"  "1239.44830464327"
# [2,] "daynight"      "1 3"    "1243.57252363355"
# [3,] "jd"            "2 3"    "1244.13557617238"
# [4,] "pres"          "1 2"    "1250.6508010682"
# lowest AIC was when none were removed, stop backwards selection here

  
# now, run it forwards
# Forward selection
# to ensure we really are testing out every potential model, work forward!
# in this case, we are building up the model, each round of the for loop we are adding an additional variable
# again, keep adding variables until the AIC of the set is increasing instead of decreasing
# "Included" = variable that was added in this round
# "Idx" = variable(s) included in the model
# ------------------------------------------------------------------------------
fwdSelection1 = matrix(0, ncol=3, nrow=NVars)
colnames(fwdSelection1) = c("Included","Idx Vars", "AIC")

## 1st round
# Include one variable at a time
for (x in 1: length (selectedCovariates)){
  gc()
  iselected = c(x)
  newformula = as.formula(paste("groupSize ~", paste(selectedCovariates[iselected], collapse = " + ")))
  m = gam(as.formula (newformula),data=dfMod,family=tw(),method="REML") 
  fwdSelection1[x,1] = namesCovariates[iselected]
  fwdSelection1[x,2] = paste(iselected,collapse=" ")
  fwdSelection1[x,3] = AIC(m)
}
fwdSelection1[order(fwdSelection1[,3],decreasing=FALSE),]
#      Included   Idx Vars AIC               
# [1,] "pres"     "3"      "1247.5931039568" 
# [2,] "daynight" "2"      "1254.4637300276" 
# [3,] "jd"       "1"      "1254.73448964047"
# lowest AIC is pres, add this into the model and run again

## 2nd round
# Include one variable at a time with variable(s) included from previous step
varIncluded = c(3) # variable included from previous step
fwdSelection2 = matrix(0, ncol=3, nrow=NVars-length(varIncluded))
colnames(fwdSelection2) = c("Included","Idx Vars", "AIC")
i = 1
for (x in 1: length (selectedCovariates)){
  if (all(x != varIncluded)){
    gc()
    iselected = c(varIncluded,x)
    iselected = iselected[order(iselected,decreasing = FALSE)]
    newformula = as.formula(paste("groupSize ~", paste(selectedCovariates[iselected], collapse = " + ")))
    m = gam(as.formula (newformula),data=dfMod,family=tw(),method="REML") 
    fwdSelection2[i,1] = paste(namesCovariates[iselected],collapse=",")
    fwdSelection2[i,2] = paste(iselected,collapse=" ")
    fwdSelection2[i,3] = AIC(m)
    i = i+1
  }
}
fwdSelection2[order(fwdSelection2[,3],decreasing=FALSE),]
#      Included        Idx Vars AIC               
# [1,] "jd,pres"       "1 3"    "1243.57252363355"
# [2,] "daynight,pres" "2 3"    "1244.13557617238"
# jd and presence have lowest AIC, add both in and proceed

## 3rd round
varIncluded = c(1,3) # variable included from previous step
fwdSelection3 = matrix(0, ncol=3, nrow=NVars-length(varIncluded))
colnames(fwdSelection3) = c("Included","Idx Vars", "AIC")
i = 1
for (x in 1: length (selectedCovariates)){
  if (all(x != varIncluded)){
    gc()
    iselected = c(varIncluded,x)
    iselected = iselected[order(iselected,decreasing = FALSE)]
    newformula = as.formula(paste("groupSize ~", paste(selectedCovariates[iselected], collapse = " + ")))
    m = gam(as.formula (newformula),data=dfMod,family=tw(),method="REML") 
    fwdSelection3[i,1] = paste(namesCovariates[iselected],collapse=",")
    fwdSelection3[i,2] = paste(iselected,collapse=" ")
    fwdSelection3[i,3] = AIC(m)
    i = i+1
  }
}
fwdSelection3[order(fwdSelection3[,3],decreasing=FALSE),]
#           Included           Idx Vars                AIC 
# "jd,daynight,pres"            "1 2 3" "1239.44830464327"
# model with everything was best, this aligns with the backwards selection!

# run the model that is the best <3
# stop here, run the model and see what comes out significant
# the full model has the lowest AIC
bestModel = gam(groupSize~
                  + s(dfMod$jd,bs='cc')
                  + dayNight
                  + presBins,
                data=dfMod,family=tw(),method='REML')
summary(bestModel)
# Family: Tweedie(p=1.99) 
# Link function: log 
# 
# Formula:
# groupSize ~ +s(dfMod$jd, bs = "cc") + dayNight + presBins
# 
# Parametric coefficients:
#             Estimate Std. Error t value Pr(>|t|)    
# (Intercept) 0.735110   0.049948  14.718  < 2e-16 ***
# dayNight1   0.130743   0.053423   2.447 0.014841 *  
# presBins    0.005357   0.001488   3.600 0.000359 ***
# ---
# Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
# 
# Approximate significance of smooth terms:
#              edf Ref.df     F p-value   
# s(dfMod$jd) 1.93      8 0.979 0.00827 **
# ---
# Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
# 
# R-sq.(adj) =  0.0551   Deviance explained = 6.52%
# -REML = 625.14  Scale est. = 0.2688    n = 388

# make the plots
plot(bestModel, all.terms=TRUE, shade=TRUE,y = )

```